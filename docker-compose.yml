services:
  # PostgreSQL Database
  db:
    image: postgres:16-alpine
    container_name: scrapingweb_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scrapingweb_network

  # Redis (para Celery)
  redis:
    image: redis:7-alpine
    container_name: scrapingweb_redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scrapingweb_network

  # Backend FastAPI
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: scrapingweb_backend
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - .:/app
      - ./exports:/app/exports
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - scrapingweb_network
    restart: unless-stopped

  # Celery Worker (procesamiento en background)
  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: scrapingweb_celery_worker
    command: celery -A app.workers.queue worker --loglevel=info
    env_file:
      - .env
    volumes:
      - .:/app
    depends_on:
      - redis
      - db
      - backend
    networks:
      - scrapingweb_network
    restart: unless-stopped

  # Celery Beat (scheduler para scraping diario)
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: scrapingweb_celery_beat
    command: celery -A app.workers.queue beat --loglevel=info
    env_file:
      - .env
    volumes:
      - .:/app
    depends_on:
      - redis
      - db
      - backend
    networks:
      - scrapingweb_network
    restart: unless-stopped

  # pgAdmin (opcional - administraci√≥n de BD)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: scrapingweb_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@scrapingweb.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - db
    networks:
      - scrapingweb_network
    restart: unless-stopped

networks:
  scrapingweb_network:
    driver: bridge

volumes:
  postgres_data:
  pgadmin_data:
